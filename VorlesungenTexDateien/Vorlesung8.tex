\documentclass[../VorlesungMaster.tex]{subfiles}

%Vorlesung 14.11.17
Beachten Sie, Der wahre Zusammenhang zwischen Y und X ist unbekannt d.h. die wahre Regressionsgerade ist unbekannt. \\
\textbf{Grund:} Schätzungen für $\hat{\beta_0}$ und$ \hat{\beta_1}$ hängen von der gewählten Trainingsmenge ab\\
\textbf{Daraus Folgt:} Die geschätzte Regressionsgeraden schwanken um die wahre Regressionsgerade 
- Koeffitzienten  $\hat{\beta_0}$ und$ \hat{\beta_1}$ sind Zufallsvariablen, welche auf Basis der gezogenen Beobachtung ($X_i,Y_i$) gemacht werden


Varianz für $\beta_1$ 
\[Var(\beta_1) = \frac{\sigma _{epsilon}^2}{\sum_{i=1}^{n}(X_i- \bar{x})^2}\]
\[\bar{\sigma_{epsilon}^2} = \frac{RSS}{n-2}\]
\[\hat{Var(\beta_1)} = \frac{RSS / (n-2)}{\sum_{i=1}^{n} (X_i - \bar{x})^2}\]

Varianz von $\beta_1$ ist klein, wenn:
\begin{enumerate}
	\item Varianz der Störgrößen klein ist
	\item Stichprobengrößen n groß ist
\end{enumerate}
\[Var(\beta_0) = \frac{\sigma_\epsilon^2  \sum x_i}{n Var(X)}\]

Das Bestimmtheitsmaß $R^2$
Wie gut ist die Schätzung der Daten anhand der gefitteten Geraden\\
$\rightarrow$ Schätzung ist dann besonders gut, wenn der Anteil von RSS an Gesamtvarianz(TSS) klein ist und somit die erklärte Varaianz möglichst groß ist

\[R^2 = \frac{\text{erklärbare Varianz}}{Gesamtvarianz}\]
\[TSS = \sum (\hat{y} - \bar{y})^2 + RSS  = \frac{TSS-RSS}{TSS}= 1 -\frac{RSS}{TSS}\]


$0 \leq R^2 \leq 1$ \\
$R^2 \approx 1$:Ein großer Anteil der Variablitität in der Zielvariablen durch (gelernte) Regressionsgerade erklärt\\
$R^2 \approx 0$: Regressionsgerade erklärt keinen großen Anteil der Varianz der Zielvariablen

\subsection{Testen ob es einen signifikanten Zusammenhang zwischen Y und X gibt}
Frage Existiert irgendein Zusammenhang zwischen X und Y, also $\beta_1 \neq 0$\\
$H_0:$ Es existiert kein Zusammenhang $ \Leftrightarrow $ $ \beta_1 = 0$\\
$H_1:$ Es existiert ein Zusammenhang $ \Leftrightarrow $ $\beta_1 \leq 1$\\

Teststaistik: $t= \frac{\hat{\beta_1}}{s.d.(\hat{\beta_1})} = \frac{\hat{\beta_1}}{\sqrt{Var(\hat{\beta_1})}} \approx t_{1-\alpha/2, n-2}$

$|t| \leq  t_{1-\alpha/2, n-2} \rightarrow H_0$ wird beibehalten

$|t| >  t_{1-\alpha/2, n-2} \rightarrow H_0$ wird abelehnt, wir können annehmen das $\beta_1 \leq 0$


\subsection{Multilinerare lineare Regression
}\begin{itemize}
	\item Erweiterung der einfachen linearen Regression auf mehreren Kovariablen $X={X_1, \ldots, X_p}$
	\item Identifiziere ein verbessertes Modell als es auf Basis einer einzelnen Kovariable möglich ist 
	\item Individuelle Effekte der Kovariablen $X_I$ können durch partielle Regressionsgeraden modelliert werden.
	\item  Jede partielle Regressionsgerade entspricht(modelliert) den Effekt von $X_i$ während alle anderen Kovariablen $X_{j \neq i}$ ihren Mittelwert annehmen
\end{itemize}

\subsubsection*{Additives multivariables lineares Regressionsmodell}
Annahme: Effekt einer Kovariablen $X_i$ auf Y ist unabhängig von allen anderen Kovariablen 
\[Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \ldots + \beta_p X_p + \epsilon\]
$ \beta_1,\ldots,\beta_p$ geben Effekte der Kovariablen $X_1, \ldots, X_p$ auf Y an.\\
p: Anzahl der Kovariablen\\ 
$ \beta_0 $ Miittelwert von Y , falls alle Koeffizienten $ \beta_j = 0 $\\
$\epsilon$ ist der Fehler $\epsilon \sim N(0, \sigma_\epsilon^2)$


\subsection*{Multiplikatives Modell}
\begin{itemize}
	\item Interaktionen zwischen den Kovariablen sind möglich
	\item D.h. partieller Effekt einer Kovariablen $X_i$ kann vom partiellen Effekt von $X_j$ abhängig sein
\end{itemize}
\[Y = \beta_0+ \beta_1X_1 + \beta_2X_2 + \beta_3 X_1X_2 + \beta_4 X_3 +\ldots \beta_{p+1}X_p + \epsilon\]

$\beta_3:$ Gibt an, inwieweit der Effekt von $X_1$ von den Werten von $X_2$ abhängt

Schätzung der Koeffizienten $\beta_1, \ldots, \beta_p$ 
Methode der kleinsten Quadrate
\[
\hat{Y} = \hat{ \beta_{p+1}} + \hat{\beta_{1}} X_1 + \ldots \hat{\beta_{p}} X_p
\]

\[ RSS = Var(\epsilon) = \sum_{i = 1}^{n} (y_i - \hat{y_i})^2\]
\[\sum(y_i - \hat{\beta_0} - \hat{\beta_1} X_1 - \ldots \hat{\beta_p} X_p)^2 \rightarrow \min\]

über partielle Ableitungen werden die Koeffizienten $\beta_i$ geschätzt

