\section{Kurzzusammenfassung}
\subsection{multiple lineare Regresseion}
\[Y_I = \beta_0 + \beta_1 x_i^{(1)} + \ldots + \beta_k x_i^{(k)} + \epsilon_i \text{ ; } i \in \{1, \ldots,n\}\]

\textbf{Problem}
\begin{itemize}
	\item \(n \approx k\)
	\item \(n < k\)
\end{itemize}
\textbf{Auswege:} \\
Variablenselektion
\begin{itemize}
	\item[\(\rightarrow\)] BSS
	\item[\(\rightarrow\)] VS (Vorwärtsselektion)
	\item[\(\rightarrow\)] RS (Rückwärtsselektion)
\end{itemize}
Regularisierung
\begin{itemize}
	\item RR (Tuning Parameter (\(\lambda > 0\) für die Stärke der Bestrafung)
	\item Lasso
\end{itemize}
\todo{\(AIC = AC + f(k^2)\)}
\todo{\(Cp: K:= {0, \ldots, k}\)\\
\(P<= K\) \\
\(|P| = p C_p\) \(\approx p \rightarrow\) dieses Modell "`am besten"' geeignet}

Modellbewertung:RSS, Mallows Cp, AIC, BIC, R$^2$ R$_{adj}^2$

\subsection{Lasso (Least Absolute Shrinkage and Selection Operator)}
Ähnlich wie Ridge Regression 
\begin{itemize}
	\item \(\lambda > 0 \)
	\item \(\sum_{i = 1}^{n}(y_i -\beta_0 - \beta_1 x_i^{(1)} - \ldots - \beta_k x_i^{(k)})^2 + \underbrace{\lambda \sum_{j = 1}^{k}|\beta_j|}_{Strafterm}
	\rightarrow_{\beta_0, \ldots, \beta_k \in \mathbb{R}} \min \)
	\item Bestrafungsterm in L$^1$-Norm (Ridge Regression L$^2$ Norm)
	\item Hauptunterschied zur Ridge Regression: $L^1$-Norm führt dazu, dass viele Koeffizienten "`=0"' geschätzt werden (Ridge-Regression "'$\approx$ 0"')
	\item einfachere Interpretierbarkeit des Modells
	\item [\(\rightarrow\)] Variablenselektion
	\item [ABER]
	\begin{itemize}
		\item Varianz der $ \hat{\beta_j} $ ist bei Lasso größer als bei Ridge
	\end{itemize}
\end{itemize}

%L^1 Norm von \beta := (\beta_1, \ldots,\beta_i)
%Allgemein: L$^P$-Norm von $\beta$\\
%\(\rightarrow ||\beta||_p = ||\beta||_{L^p} = \sqrt{\sum_{j = 1}^{k} |\beta_j|^p}\)\\
%\(\Leftrightarrow ||\beta||_p^p = \sum_{j=1}^{k}|\beta_j|^P\)

\subsection{Wahl des Tuningparameters $\lambda$}
\textbf{Kreuzvalidierung:}
\begin{enumerate}
	\item Wähle ein Gitter von möglichen $\lambda$-Werten
	\item Berechne für jeden dieser Werte den Kreuzvalidierten Fehler
	\item Wähle das \(\lambda\) mit dem kleinsten Fehler
	\item Berechne mit dem "`finalen"' \( \lambda \) das Modell erneut (mit kompletten Datensatz)
\end{enumerate}


\section{Kreuzvalidierung}
\textbf{\underline{Beispiel:}}
	\begin{itemize}
		\item ($X_i$, $Y_i$)$_{i=1}^n$ - Stichprobe
		\item $X_i$ Körpergröße
		\item $Y_i$ -Körpergewiche
		\item Modell: 
	\end{itemize}
		\[Y_I = \beta_0 + \beta_1 x_i\epsilon_i \text{ ; } i \in \{1, \ldots,n\}\]
\begin{itemize}
\item bestimmen $\hat{\beta_0}$ und $\hat{\beta_1}$ über KQM
\item [\(\rightarrow\)] Wie gut sind die schätzungen
\end{itemize}


\[ MSE := \frac{1}{n} \sum_{i = 1}^{n} (y_i - \hat{y_i})^2 \text{  (Mean Squared Error)}\]

\begin{itemize}
	\item[\( \rightarrow \)] gilt nur für vorliegende Stichprobe
	\item[\( \rightarrow \)] Wie gut sind diese Schätzungen für zukünftige Daten?
\end{itemize}

\subsection{Vorgehen}
\begin{itemize}
	\item Man verwendet einen Teil der Stichprobe als \underline{Trainingssatz} und den anderen Teil als \underline{Validierungsdatensatz}
	\item[\( \rightarrow \)] Den Trainingsdatensatz zum schätzen der Parameter
	\item[\( \rightarrow \)] Den Validierungsdatensatz zum überprüfen der Vorhersagegüte
\end{itemize}

\textbf{\underline{Beispiel}(Fortsetzung):}
\begin{itemize}
	\item $(x_i, y_i)_i \in I_T$ - Trainingsdaten
	\item $(x_i,y_i)_i \in I_V$ -Validierungsdaten
\end{itemize}
mit $ I_T,  I_V \subseteq \{1,\ldots,n\}$   und $I_T \cap I_V = \emptyset$
	
\begin{itemize}
	\item $ \hat{\beta_0}^T $, $ \hat{\beta_1}^T $ - Schätzer für $\beta_0$ und  $\beta_1$ unter Verwendung von $ (x_i $, $ y_i $$ )_{i \in I_T} $
	\item mittlerer quadratischer Fehler über Validierungsdaten
\end{itemize}

\[MSE_V := \frac{1}{|I_V|} \sum_{i \in I_V}(Y_i - \underbrace{(  \hat{\beta_0}^T +  \hat{\beta_1}^T x_i)}_{:= \hat{y_i}^{(T)}})^2\]

\textbf{Problem:} Bias durch "`ungünstige"' Aufteilung in Trainings und Validierungsdaten $\rightarrow$
unter bzw. Überschätzen des MSE

\textbf{Lösung:} m-maliges Aufteilen der gesamten Stichprobe in Trainings und Validierungsdaten

für \(L=1,\ldots, m\) jeweils Parameter schätzen und mittleren quadratischen Fehler berechnen. Anschließend mittleren quadratischen Fehler (MSE) bestimmen

$\rightarrow$ Aufteilung jeweils möglichst zufällig wählen

\textbf{Beispiel} Fortsetzung:
\begin{itemize}
	\item m mal in trainings und Validierungsdaten aufteilen
	\item $ (x_i, y_i)_{i \in I_T^{(1)}} , (x_i,y_i)_{i \in I_V^{(1)}} $ $ \ldots $
	\item $ (x_i, y_i)_{i \in I_T^{(m)} }, (x_i,y_i)_{i \in I_V^{(m)}} $
	\item bestimmen jeweils  $\hat{\beta_0}^{(T,l)}$, $\hat{\beta_1}^{(T,l)}$ und 
	\[ MSE_V^{(l)} := \frac{1}{|I_V^{(l)}|} \sum_{i \in I_V^{(l)}}(y_i - (\hat{\beta_0}^{(T,l)} + \hat{\beta_1}^{(T,l)} x_i))^2  \]
	\item für $l = 1, \ldots, m$
	\item bestimme den gemittelten MSE
	\[MSE_V^m := \frac{1}{m} \sum_{k=1}^{m} MSE_V^{(k)}\]
\end{itemize}

\subsection{Mögliche Aufteilungen}
\subsubsection{Leave one out Cross Validation}
Beispiel: Fortsetzung
\begin{itemize}
	\item für \(l = 1,\ldots,n\) 
	\item $(x_i, y_i)_i \in \{1, \ldots, n \} \setminus \{l\}$ Trainingsdatensatz
	\item $(x_i, y_i)_i = l$ Validierungsdatensatz
	\[MSE_V^{(l)} = (y_l - (\hat{\beta_0}^{(T, \{l\})} + \hat{\beta_1}^{(T, \{l\})} x_i)) \text{ für } l = 1,\ldots ,n\]	
	\[MSE_v^n := \frac{1}{n}\sum_{l = 1}^{n} MSE_V^{(l)}\]
\end{itemize}

\subsection{k-fache Kreusvalidierung}
\textbf{\underline{Beispiel} (Fortsetzung):}

Aufteilung in K Blöcke:
\[(x_i, y_i)_{i \in I^{(k)}} \text{ für }  k = 1, .., K \] 
\[\text{mit } I^{(k_1)} \cap I^{(k_2)} = \emptyset \text{ für } k_1, k_2 \in {1, \ldots ,K} \text{ mit } k_1 \neq k_2 \]
\[ \text{und } |I^{(K)}| = \begin{cases}
\frac{n}{K} &, n \mod K= 0\\
n \mod K &, n \mod K \neq 0
\end{cases}
\]
\[\text{und } |I^{(k)}| = \frac{n - |I^{(k)}|}{K-1} \text{ für } k = \{1, \ldots ,K - 1\} \]

möglichst \(|I^{(K)}| \approx |I^{(k)}|\)für \(k = \{1, \ldots ,K-1\}\)\\


Für \(k = 1, \ldots, K\) 
\begin{itemize}
	\item[] \((x_i, y_i)_{ i \in I^{(l)}}, l \in \{1, \ldots, K\}\setminus \{k\}\) - Trainingsdaten
	\item[] \((x_i, y_i)_{ i \in I^{(k)}} \) - Validierungsdatensatz
	\item Bemerkung \(K=n \rightarrow LOOCV\) 	
	\item[\(\rightarrow\)]\(MSE_V^{(k)} = \frac{1}{|I^{(k)}|} \sum_{i \in I^{(k)}} ( y_i -( \hat{\beta_0}^{(T,k)} + \hat{\beta_1}^{(T,k)}  x_i))^2\) 
	\item [\(\rightarrow\)]
	\(MSE_V^K = \frac{1}{K} \sum_{k=1}^{K} MSE_V^{(k)}\) 
	\item üblich K=5 oder K=10
\end{itemize}


